# Глава 3: Продвинутые техники работы с LangChain

В этой главе вы углубитесь в продвинутые возможности LangChain, которые позволяют создавать сложные AI-системы для автоматизации и аналитики. Мы рассмотрим цепочки, агентов, контекстную память и кастомные инструменты, а также их интеграцию с векторными базами данных, таких как Qdrant.

## 3.1 Цепочки (Chains) в LangChain

Цепочки в LangChain позволяют комбинировать промпты, LLM и внешние данные в последовательные пайплайны для обработки сложных задач. Они поддерживают модульность, позволяя настраивать этапы обработки, такие как извлечение контекста или форматирование вывода. Это делает их идеальными для задач, требующих многоэтапной логики, например, анализа текстов или генерации отчетов.

**Пример**: Создание цепочки для анализа пользовательского запроса с извлечением контекста из векторной базы Qdrant.

```python
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Qdrant
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough

docs = ["AI повышает эффективность процессов.", "Автоматизация снижает затраты."]
embeddings = OpenAIEmbeddings()
vectorstore = Qdrant.from_texts(docs, embeddings, location=":memory:")
retriever = vectorstore.as_retriever()
llm = ChatOpenAI(model="gpt-3.5-turbo")
prompt = PromptTemplate(input_variables=["context", "question"], template="Контекст: {context}\nВопрос: {question}\nОтвет:")
chain = {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
response = chain.invoke("Как AI влияет на бизнес?")
print(response.content)
```

## 3.2 Кастомные инструменты

Кастомные инструменты в LangChain позволяют расширить функциональность агентов, подключая внешние API, базы данных или пользовательские функции. Они особенно полезны для автоматизации бизнес-процессов, где требуется интеграция с корпоративными системами, такими как CRM, ERP или внутренние базы данных. Кастомные инструменты дают возможность адаптировать поведение агента под конкретные задачи, такие как получение данных из внешних источников, выполнение вычислений или автоматизация рутинных операций. Например, вы можете создать инструмент для извлечения данных о сотрудниках из корпоративной базы или для отправки уведомлений в корпоративный мессенджер.

**Пример**: Кастомный инструмент для получения данных о сотруднике из тестового API (DummyJSON).

```python
import requests
from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType

def get_employee_info(employee_id: str) -> str:
    try:
        response = requests.get(f"https://dummyjson.com/users/{employee_id}")
        if response.status_code == 200:
            data = response.json()
            return f"Сотрудник: {data['firstName']} {data['lastName']}, {data['age']} лет, Email: {data['email']}"
        else:
            return "Ошибка: сотрудник не найден"
    except Exception as e:
        return f"Ошибка при запросе: {str(e)}"

llm = ChatOpenAI(model="gpt-3.5-turbo")
tools = [
    Tool(
        name="GetEmployeeInfo",
        func=get_employee_info,
        description="Получает информацию о сотруднике по его ID"
    )
]
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)
response = agent.run("Найди информацию о сотруднике с ID 5")
print(response)
```

**Рекомендации по созданию кастомных инструментов**:
- **Валидация входных данных**: Всегда проверяйте входные параметры, чтобы избежать ошибок. Например, в инструменте умножения проверяйте, что входные данные — это числа.
- **Обработка ошибок**: Включайте обработку исключений, чтобы агент мог корректно реагировать на сбои, как в примере с API.
- **Четкие описания**: Пишите подробные описания для параметра `description` в `Tool`, чтобы LLM правильно интерпретировал назначение инструмента.
- **Модульность**: Создавайте инструменты, которые можно повторно использовать в разных агентах или сценариях.
- **Безопасность**: Если инструмент взаимодействует с внешними API, убедитесь, что доступ ограничен и защищен (например, используйте токены API).

## 3.3 Агенты с ReAct и кастомными инструментами

Агенты в LangChain — это интеллектуальные компоненты, которые используют LLM для принятия решений и выбора подходящих инструментов на основе запроса пользователя. ReAct (Reasoning and Acting) — это стратегия, при которой агент сначала рассуждает о задаче, а затем выбирает и выполняет соответствующий инструмент. Это особенно полезно для задач, требующих логического вывода, таких как математические вычисления или обработка сложных запросов. В примере ниже агент использует кастомный инструмент для умножения чисел, чтобы решить задачу, связанную с подсчетом конфет. Параметры `verbose=True` и `max_iterations=5` обеспечивают отображение шагов рассуждений и ограничение числа попыток, а `handle_parsing_errors=True` помогает обрабатывать ошибки парсинга.

**Пример**: Настройка агента с ReAct для выполнения математических вычислений.

```python
from langchain_openai import ChatOpenAI
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentType

def multiply(a: str) -> str:
    nums = [int(x) for x in a.split(",")]
    return str(nums[0] * nums[1])

tools = [
    Tool(
        name="Multiply",
        func=multiply,
        description="Умножает два числа, переданных через запятую",
    )
]

llm = ChatOpenAI(model="gpt-3.5-turbo")
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    max_iterations=5,
    handle_parsing_errors=True,
)
response = agent.run("Три друга решили купить по пять конфет каждый. Сколько всего конфет они купят?")
print("Ответ агента:", response)
```

## 3.4 Контекстная память (Memory)

Контекстная память в LangChain сохраняет историю взаимодействия, позволяя агенту или цепочке учитывать предыдущие запросы. Это критически важно для чат-ботов, где диалог должен быть последовательным и контекстно-зависимым. LangChain предоставляет несколько типов памяти, таких как `ConversationBufferMemory`, для поддержки разных сценариев.

**Пример**: Использование памяти для поддержания диалога в чат-боте.

```python
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

llm = ChatOpenAI(model="gpt-3.5-turbo")
memory = ConversationBufferMemory()
conversation = ConversationChain(llm=llm, memory=memory)
conversation.run("Привет, я изучаю AI.")
print(conversation.run("Что я сказал ранее?"))
```

## 3.5 Интеграция с векторными базами данных

LangChain легко интегрируется с векторными базами, такими как Qdrant, для реализации RAG-систем. Это позволяет эффективно извлекать релевантные данные для последующей обработки LLM. Такие навыки востребованы в задачах анализа больших объемов текстов, например, в юридической или финансовой аналитике. Qdrant обеспечивает высокую производительность и масштабируемость, что делает его предпочтительным выбором для корпоративных приложений после отказа от Chroma из-за проблем с совместимостью.

## Упражнения

1. **Анализ финансовых отчетов с RAG**: Создайте цепочку в LangChain, использующую Qdrant для хранения финансовых отчетов компании (например, текстов: "Выручка в Q1 2025 выросла на 15%." и "Затраты на маркетинг сократились на 10%."). Настройте кастомный промпт, который извлекает контекст из Qdrant и отвечает на вопрос: "Каковы ключевые финансовые изменения в Q1 2025?" с форматированным выводом в виде списка.
2. **Агент для управления данными сотрудников**: Разработайте агента с двумя кастомными инструментами: один для получения данных о сотруднике по ID (используя API https://dummyjson.com/users/{id}), второй для вычисления возраста сотрудника в месяцах на основе даты рождения (поле `birthDate` в формате YYYY-MM-DD). Выполните запрос: "Получи информацию о сотруднике с ID 7 и рассчитай его возраст в месяцах на текущую дату."
3. **Чат-бот с памятью и динамическими инструментами**: Настройте чат-бота с использованием `ConversationBufferMemory`, который выбирает между двумя кастомными инструментами: один возвращает текущую дату, другой — случайное число от 1 до 100. Выполните последовательные запросы: "Какая сегодня дата?", "Какое число ты мне дашь?", "Что я спрашивал первым?".

## Рекомендации по выполнению

- Понадобятся библиотеки `langchain`, `langchain-openai`, `langchain-community`, `qdrant-client`.
- Настройте API-ключ OpenAI через переменную окружения.
- Для упражнения 1 убедитесь, что Qdrant настроен корректно.